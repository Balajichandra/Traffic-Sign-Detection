{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f4c69cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To allocate memorey for gpu(here we are using 50%)\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "\n",
    "config = ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.5\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "04b74c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator,load_img\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f4da23af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pickle\n",
    "import cv2\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd2a050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters\n",
    "path = \"myData/\"\n",
    "label = \"labels.csv\"\n",
    "batch_size_val = 32\n",
    "steps_per_epoch_val = 2000\n",
    "epoch_val = 10\n",
    "imageDimension = (32,32,3)\n",
    "testratio = 0.2\n",
    "validationratio = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "926bec22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no of classes  detected: 43\n"
     ]
    }
   ],
   "source": [
    "#importing images\n",
    "count = 0\n",
    "images = []\n",
    "noofclass = []\n",
    "mylist = os.listdir(path)\n",
    "print(\"Total no of classes  detected:\",len(mylist))\n",
    "#print(\":\",len())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a6846fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "NoClass = len(mylist)\n",
    "for x in range(0,len(mylist)):\n",
    "    myPicList = os.listdir(path+\"/\"+str(count))\n",
    "    for y in myPicList:\n",
    "        curImg = cv2.imread(path+\"/\"+str(count)+\"/\"+y)\n",
    "        images.append(curImg)\n",
    "        noofclass.append(count)\n",
    "    count+=1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c0f6c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.array(images)\n",
    "noofclass = np.array(noofclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eb3fdd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[[129 138 152]\n",
      "   [131 138 151]\n",
      "   [131 137 151]\n",
      "   ...\n",
      "   [153 127 119]\n",
      "   [131 116 111]\n",
      "   [132 124 123]]\n",
      "\n",
      "  [[128 138 160]\n",
      "   [134 142 163]\n",
      "   [134 140 164]\n",
      "   ...\n",
      "   [140 128 131]\n",
      "   [137 128 129]\n",
      "   [133 127 127]]\n",
      "\n",
      "  [[146 156 172]\n",
      "   [147 154 169]\n",
      "   [151 155 175]\n",
      "   ...\n",
      "   [127 125 127]\n",
      "   [128 126 126]\n",
      "   [130 126 126]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 93  94  98]\n",
      "   [ 93  94  99]\n",
      "   [ 93  95  98]\n",
      "   ...\n",
      "   [101 104 102]\n",
      "   [104 106 106]\n",
      "   [100 102 102]]\n",
      "\n",
      "  [[ 91  94  89]\n",
      "   [ 92  95  89]\n",
      "   [ 91  94  93]\n",
      "   ...\n",
      "   [ 98 102 101]\n",
      "   [100 106 106]\n",
      "   [ 96 101 101]]\n",
      "\n",
      "  [[101 107  91]\n",
      "   [124 128 107]\n",
      "   [100 101  94]\n",
      "   ...\n",
      "   [ 97 101 102]\n",
      "   [100 105 105]\n",
      "   [ 97 101 100]]]\n",
      "\n",
      "\n",
      " [[[120 125 129]\n",
      "   [121 122 127]\n",
      "   [123 123 128]\n",
      "   ...\n",
      "   [133 132 135]\n",
      "   [118 119 118]\n",
      "   [116 118 119]]\n",
      "\n",
      "  [[124 127 132]\n",
      "   [124 126 130]\n",
      "   [122 124 130]\n",
      "   ...\n",
      "   [143 143 150]\n",
      "   [126 124 125]\n",
      "   [122 118 119]]\n",
      "\n",
      "  [[130 131 143]\n",
      "   [127 131 145]\n",
      "   [123 128 143]\n",
      "   ...\n",
      "   [171 168 175]\n",
      "   [155 149 155]\n",
      "   [150 138 145]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 93  95  96]\n",
      "   [ 93  96  96]\n",
      "   [ 94  95  97]\n",
      "   ...\n",
      "   [115 121 129]\n",
      "   [ 95 101 104]\n",
      "   [ 95  98  99]]\n",
      "\n",
      "  [[ 85  88  90]\n",
      "   [ 87  90  91]\n",
      "   [ 89  91  95]\n",
      "   ...\n",
      "   [118 124 131]\n",
      "   [ 95 100 105]\n",
      "   [ 97  98 101]]\n",
      "\n",
      "  [[ 88  88  89]\n",
      "   [ 85  88  88]\n",
      "   [ 86  91  94]\n",
      "   ...\n",
      "   [116 122 128]\n",
      "   [ 94  99 101]\n",
      "   [ 96  97  97]]]\n",
      "\n",
      "\n",
      " [[[169 177 185]\n",
      "   [144 149 164]\n",
      "   [128 131 141]\n",
      "   ...\n",
      "   [127 109  97]\n",
      "   [136 122 111]\n",
      "   [159 158 152]]\n",
      "\n",
      "  [[173 182 193]\n",
      "   [144 149 168]\n",
      "   [125 128 138]\n",
      "   ...\n",
      "   [129 122 121]\n",
      "   [135 127 126]\n",
      "   [157 158 155]]\n",
      "\n",
      "  [[165 175 180]\n",
      "   [145 149 162]\n",
      "   [124 127 133]\n",
      "   ...\n",
      "   [118 118 122]\n",
      "   [127 125 127]\n",
      "   [154 157 157]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[163 171 183]\n",
      "   [128 136 156]\n",
      "   [ 98 105 115]\n",
      "   ...\n",
      "   [ 98 100 103]\n",
      "   [129 121 124]\n",
      "   [157 156 159]]\n",
      "\n",
      "  [[163 170 182]\n",
      "   [126 133 154]\n",
      "   [ 94 101 109]\n",
      "   ...\n",
      "   [ 93  94  94]\n",
      "   [125 116 117]\n",
      "   [156 154 157]]\n",
      "\n",
      "  [[166 168 179]\n",
      "   [127 130 151]\n",
      "   [ 96 100 107]\n",
      "   ...\n",
      "   [ 93  93  93]\n",
      "   [125 114 114]\n",
      "   [158 155 156]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[198 207 219]\n",
      "   [194 206 218]\n",
      "   [193 207 223]\n",
      "   ...\n",
      "   [205 218 234]\n",
      "   [208 219 232]\n",
      "   [209 221 235]]\n",
      "\n",
      "  [[196 206 218]\n",
      "   [190 206 218]\n",
      "   [191 206 219]\n",
      "   ...\n",
      "   [203 216 230]\n",
      "   [204 216 231]\n",
      "   [206 218 234]]\n",
      "\n",
      "  [[191 202 217]\n",
      "   [188 202 220]\n",
      "   [191 204 218]\n",
      "   ...\n",
      "   [201 213 228]\n",
      "   [200 214 231]\n",
      "   [201 215 231]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[120 115 116]\n",
      "   [141 134 133]\n",
      "   [162 159 159]\n",
      "   ...\n",
      "   [167 189 191]\n",
      "   [149 158 163]\n",
      "   [147 148 157]]\n",
      "\n",
      "  [[148 145 147]\n",
      "   [158 152 158]\n",
      "   [160 154 152]\n",
      "   ...\n",
      "   [ 85 101  96]\n",
      "   [ 98  95  87]\n",
      "   [134 131 132]]\n",
      "\n",
      "  [[125 125 129]\n",
      "   [144 141 140]\n",
      "   [166 159 150]\n",
      "   ...\n",
      "   [124 123 128]\n",
      "   [121 117 114]\n",
      "   [110 104  93]]]\n",
      "\n",
      "\n",
      " [[[ 96 107 113]\n",
      "   [ 58  69  71]\n",
      "   [ 59  60  58]\n",
      "   ...\n",
      "   [209 222 237]\n",
      "   [210 224 236]\n",
      "   [209 222 235]]\n",
      "\n",
      "  [[ 79  83  82]\n",
      "   [ 65  71  73]\n",
      "   [ 60  62  63]\n",
      "   ...\n",
      "   [209 220 235]\n",
      "   [208 221 235]\n",
      "   [208 220 233]]\n",
      "\n",
      "  [[ 66  63  62]\n",
      "   [ 78  77  77]\n",
      "   [ 60  65  67]\n",
      "   ...\n",
      "   [206 216 232]\n",
      "   [205 217 231]\n",
      "   [204 218 231]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 23  22  17]\n",
      "   [ 30  29  25]\n",
      "   [ 36  41  42]\n",
      "   ...\n",
      "   [180 181 189]\n",
      "   [185 185 191]\n",
      "   [208 206 212]]\n",
      "\n",
      "  [[ 22  18  16]\n",
      "   [ 27  23  24]\n",
      "   [ 28  32  35]\n",
      "   ...\n",
      "   [172 174 182]\n",
      "   [182 180 185]\n",
      "   [201 205 213]]\n",
      "\n",
      "  [[ 21  18  19]\n",
      "   [ 25  22  25]\n",
      "   [ 23  25  29]\n",
      "   ...\n",
      "   [179 178 182]\n",
      "   [186 189 195]\n",
      "   [162 179 189]]]\n",
      "\n",
      "\n",
      " [[[215 226 240]\n",
      "   [217 229 243]\n",
      "   [217 229 245]\n",
      "   ...\n",
      "   [205 211 225]\n",
      "   [201 208 222]\n",
      "   [198 202 212]]\n",
      "\n",
      "  [[207 218 232]\n",
      "   [212 221 236]\n",
      "   [215 226 240]\n",
      "   ...\n",
      "   [175 184 194]\n",
      "   [174 183 193]\n",
      "   [157 165 173]]\n",
      "\n",
      "  [[185 192 206]\n",
      "   [201 207 222]\n",
      "   [211 222 236]\n",
      "   ...\n",
      "   [145 151 149]\n",
      "   [151 165 164]\n",
      "   [117 130 139]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[ 67  80  86]\n",
      "   [ 62  65  68]\n",
      "   [ 50  48  45]\n",
      "   ...\n",
      "   [ 30  29  29]\n",
      "   [ 41  31  34]\n",
      "   [ 25  23  26]]\n",
      "\n",
      "  [[ 59  66  68]\n",
      "   [ 50  53  56]\n",
      "   [ 38  39  41]\n",
      "   ...\n",
      "   [ 30  26  27]\n",
      "   [ 32  25  25]\n",
      "   [ 22  19  19]]\n",
      "\n",
      "  [[ 33  34  34]\n",
      "   [ 30  31  31]\n",
      "   [ 38  36  37]\n",
      "   ...\n",
      "   [ 24  23  22]\n",
      "   [ 26  24  27]\n",
      "   [ 21  19  21]]]]\n"
     ]
    }
   ],
   "source": [
    "print(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6ae79c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  0  0 ... 42 42 42]\n"
     ]
    }
   ],
   "source": [
    "print(noofclass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c41fd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "xtrain,xtest,ytrain,ytest = train_test_split(images,noofclass,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5da900d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain,Xval,Ytrain,Yval = train_test_split(xtrain,ytrain,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ac661a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ClassId</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Speed limit (20km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Speed limit (30km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Speed limit (50km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Speed limit (60km/h)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Speed limit (70km/h)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ClassId                  Name\n",
       "0        0  Speed limit (20km/h)\n",
       "1        1  Speed limit (30km/h)\n",
       "2        2  Speed limit (50km/h)\n",
       "3        3  Speed limit (60km/h)\n",
       "4        4  Speed limit (70km/h)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#read csv files\n",
    "data = pd.read_csv('labels.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6203dcb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "78ef314c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing the image\n",
    "def preprocess(img):\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    img = cv2.equalizeHist(img)\n",
    "    img = img/255\n",
    "    return img\n",
    "Xtrain = np.array(list(map(preprocess,Xtrain)))\n",
    "Xval = np.array(list(map(preprocess,Xval)))\n",
    "xtest = np.array(list(map(preprocess,xtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76860f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = Xtrain.reshape(Xtrain.shape[0],Xtrain.shape[1],Xtrain.shape[2],1)\n",
    "Xval   = Xval.reshape(Xval.shape[0],Xval.shape[1],Xval.shape[2],1)\n",
    "xtest  = xtest.reshape(xtest.shape[0],xtest.shape[1],xtest.shape[2],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b43c349a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Augmentation\n",
    "dataGen = ImageDataGenerator(width_shift_range=0.1,height_shift_range=0.1,zoom_range=0.2,shear_range=0.1,rotation_range=10)\n",
    "dataGen.fit(Xtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6702151",
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = dataGen.flow(Xtrain,Ytrain,batch_size=20)\n",
    "xbatch,ybatch = next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8d951417",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytrain = to_categorical(Ytrain,NoClass)\n",
    "Yval = to_categorical(Yval,NoClass)\n",
    "ytest = to_categorical(ytest,NoClass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eb0ddada",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size_val=50  # how many to process together\n",
    "steps_per_epoch_val=2000\n",
    "epochs_val=10\n",
    "imageDimesions = (32,32,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9faa892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_9 (Conv2D)            (None, 28, 28, 60)        1560      \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 24, 24, 60)        90060     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 12, 12, 60)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 10, 10, 30)        16230     \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 8, 8, 30)          8130      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 4, 4, 30)          0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4, 4, 30)          0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 480)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 500)               240500    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 43)                21543     \n",
      "=================================================================\n",
      "Total params: 378,023\n",
      "Trainable params: 378,023\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/10\n",
      "2000/2000 [==============================] - 49s 25ms/step - loss: 1.2035 - accuracy: 0.6446 - val_loss: 0.1303 - val_accuracy: 0.9652\n",
      "Epoch 2/10\n",
      "2000/2000 [==============================] - 31s 16ms/step - loss: 0.4111 - accuracy: 0.8714 - val_loss: 0.0577 - val_accuracy: 0.9846\n",
      "Epoch 3/10\n",
      "2000/2000 [==============================] - 36s 18ms/step - loss: 0.2877 - accuracy: 0.9098 - val_loss: 0.0587 - val_accuracy: 0.9840\n",
      "Epoch 4/10\n",
      "2000/2000 [==============================] - 31s 15ms/step - loss: 0.2371 - accuracy: 0.9262 - val_loss: 0.0303 - val_accuracy: 0.9914\n",
      "Epoch 5/10\n",
      "2000/2000 [==============================] - 37s 18ms/step - loss: 0.2030 - accuracy: 0.9375 - val_loss: 0.0251 - val_accuracy: 0.9935\n",
      "Epoch 6/10\n",
      "2000/2000 [==============================] - 32s 16ms/step - loss: 0.1768 - accuracy: 0.9453 - val_loss: 0.0350 - val_accuracy: 0.9908\n",
      "Epoch 7/10\n",
      "2000/2000 [==============================] - 32s 16ms/step - loss: 0.1640 - accuracy: 0.9496 - val_loss: 0.0312 - val_accuracy: 0.9914\n",
      "Epoch 8/10\n",
      "2000/2000 [==============================] - 31s 15ms/step - loss: 0.1513 - accuracy: 0.9538 - val_loss: 0.0250 - val_accuracy: 0.9926\n",
      "Epoch 9/10\n",
      "2000/2000 [==============================] - 33s 17ms/step - loss: 0.1425 - accuracy: 0.9558 - val_loss: 0.0249 - val_accuracy: 0.9919\n",
      "Epoch 10/10\n",
      "2000/2000 [==============================] - 32s 16ms/step - loss: 0.1396 - accuracy: 0.9578 - val_loss: 0.0329 - val_accuracy: 0.9899\n"
     ]
    }
   ],
   "source": [
    "def myModel():\n",
    "    no_Of_Filters=60\n",
    "    size_of_Filter=(5,5) # THIS IS THE KERNEL THAT MOVE AROUND THE IMAGE TO GET THE FEATURES.\n",
    "                         # THIS WOULD REMOVE 2 PIXELS FROM EACH BORDER WHEN USING 32 32 IMAGE\n",
    "    size_of_Filter2=(3,3)\n",
    "    size_of_pool=(2,2)  # SCALE DOWN ALL FEATURE MAP TO GERNALIZE MORE, TO REDUCE OVERFITTING\n",
    "    no_Of_Nodes = 500   # NO. OF NODES IN HIDDEN LAYERS\n",
    "    model= Sequential()\n",
    "    model.add((Conv2D(no_Of_Filters,size_of_Filter,input_shape=(imageDimesions[0],imageDimesions[1],1),activation='relu')))  # ADDING MORE CONVOLUTION LAYERS = LESS FEATURES BUT CAN CAUSE ACCURACY TO INCREASE\n",
    "    model.add((Conv2D(no_Of_Filters, size_of_Filter, activation='relu')))\n",
    "    model.add(MaxPooling2D(pool_size=size_of_pool)) # DOES NOT EFFECT THE DEPTH/NO OF FILTERS\n",
    " \n",
    "    model.add((Conv2D(no_Of_Filters//2, size_of_Filter2,activation='relu')))\n",
    "    model.add((Conv2D(no_Of_Filters // 2, size_of_Filter2, activation='relu')))\n",
    "    model.add(MaxPooling2D(pool_size=size_of_pool))\n",
    "    model.add(Dropout(0.5))\n",
    " \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(no_Of_Nodes,activation='relu'))\n",
    "    model.add(Dropout(0.5)) # INPUTS NODES TO DROP WITH EACH UPDATE 1 ALL 0 NONE\n",
    "    model.add(Dense(NoClass,activation='softmax')) # OUTPUT LAYER\n",
    "    # COMPILE MODEL\n",
    "    model.compile(Adam(lr=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    " \n",
    " \n",
    "############################### TRAIN\n",
    "model = myModel()\n",
    "print(model.summary())\n",
    "history=model.fit_generator(dataGen.flow(Xtrain,Ytrain,batch_size=batch_size_val),steps_per_epoch=steps_per_epoch_val,epochs=epochs_val,validation_data=(Xval,Yval),shuffle=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e209a904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('traffic_sign.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd974ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
